{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "\n",
    "def split_dataframe_on_blink(df):\n",
    "    \"\"\"Split the DataFrame into segments based on 'blink' events in the 'Elements' column.\"\"\"\n",
    "    # Identify indices where the 'Elements' column equals \"blink\"\n",
    "    blink_indices = df.index[df[\"Elements\"] == \"blink\"].tolist()\n",
    "\n",
    "    segments = []\n",
    "    start = 0\n",
    "    # Iterate over each blink index to split the DataFrame\n",
    "    for blink_idx in blink_indices:\n",
    "        # Include the blink row in the current segment\n",
    "        segment = df.iloc[start:blink_idx].reset_index(drop=True)\n",
    "        segments.append(segment)\n",
    "        # Update the starting index for the next segment to the row following the blink\n",
    "        start = blink_idx + 1\n",
    "\n",
    "    # If there are rows after the last blink, add them as the final segment\n",
    "    if start < len(df):\n",
    "        segments.append(df.iloc[start:].reset_index(drop=True))\n",
    "\n",
    "    assert len(segments) > 0\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "def compute_real_sfreq(df):\n",
    "    \"\"\"Compute the real sampling frequency from the TimeStamp column.\"\"\"\n",
    "\n",
    "    # Calculate sampling frequency from TimeStamp column\n",
    "    # Convert timestamps from string format (HH:MM:SS.mmm) to seconds\n",
    "    def time_to_seconds(time_str):\n",
    "        # Split the time string into hours, minutes, and seconds (with milliseconds)\n",
    "        hours, minutes, seconds = time_str.split(\":\")\n",
    "        # Convert to total seconds\n",
    "        total_seconds = (int(hours) * 3600) + (int(minutes) * 60) + float(seconds)\n",
    "        return total_seconds\n",
    "\n",
    "    # Apply conversion to all timestamps\n",
    "    timestamps_seconds = df[\"TimeStamp\"].apply(time_to_seconds).values\n",
    "\n",
    "    # Calculate time differences between consecutive samples (in seconds)\n",
    "    time_diffs = np.diff(timestamps_seconds)\n",
    "\n",
    "    # Calculate sampling frequency as 1 / average time difference\n",
    "    avg_time_diff = np.mean(time_diffs)\n",
    "    sfreq = 1.0 / avg_time_diff if avg_time_diff > 0 else 256.0\n",
    "\n",
    "    return sfreq\n",
    "\n",
    "\n",
    "def load_csv_to_raw(csv_file, sfreq, do_compute_sfreq=True):\n",
    "    \"\"\"Load an EEG CSV file and convert it to an MNE Raw object.\"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    computed_sfreqs = []\n",
    "    if do_compute_sfreq:\n",
    "        dfs = split_dataframe_on_blink(df.copy())\n",
    "        for sdf in dfs:\n",
    "            without_blink_freq = compute_real_sfreq(sdf)\n",
    "            computed_sfreqs.append(without_blink_freq)\n",
    "    else:\n",
    "        computed_sfreqs.append(sfreq)\n",
    "\n",
    "    if \"Elements\" in df.columns:\n",
    "        df = df[df[\"Elements\"] != \"blink\"]\n",
    "\n",
    "    # First column is TimeStamp, exclude last two columns (Battery, Elements)\n",
    "    data = df.iloc[:, 1:-2].values.T  # shape becomes (n_channels, n_samples)\n",
    "    ch_names = df.columns[1:-2].tolist()\n",
    "\n",
    "    # Create channel info; all channels are EEG\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=[\"eeg\"] * len(ch_names))\n",
    "    raw = mne.io.RawArray(data, info, verbose=None)\n",
    "    return raw, computed_sfreqs\n",
    "\n",
    "\n",
    "def load_all_data(base_dir, sfreq, do_compute_sfreq):\n",
    "    \"\"\"Load all EEG data from the given base directory.\"\"\"\n",
    "    categories = [\"Read\", \"See\", \"Translate\", \"Update\"]\n",
    "\n",
    "    computed_sfreqs = []\n",
    "\n",
    "    data = {}\n",
    "    for cat in categories:\n",
    "        cat_data = {}\n",
    "        cat_dir = os.path.join(base_dir, cat)\n",
    "        csv_files = glob.glob(os.path.join(cat_dir, \"*.csv\"))\n",
    "        print(f'Category \"{cat}\": found {len(csv_files)} files.')\n",
    "        for i, f in enumerate(csv_files):\n",
    "            if i > 10:\n",
    "                break\n",
    "            person, order, seq = re.search(r\"(P\\d{2})-(\\d{2})-(S\\d{3})\", f).groups()\n",
    "            if person not in cat_data:\n",
    "                cat_data[person] = {}\n",
    "\n",
    "            raw, computed_sfreq = load_csv_to_raw(f, sfreq, do_compute_sfreq)\n",
    "            computed_sfreqs.extend(computed_sfreq)\n",
    "            cat_data[person][seq] = raw\n",
    "\n",
    "        data[cat] = cat_data\n",
    "\n",
    "    computed_sfreqs = np.array(computed_sfreqs)\n",
    "    print(computed_sfreqs)\n",
    "    freq = {\n",
    "        \"expected\": sfreq,\n",
    "        \"computed_avg\": float(np.average(computed_sfreqs)),\n",
    "        \"computed_std\": float(np.std(computed_sfreqs)),\n",
    "        \"computed_min\": float(np.min(computed_sfreqs)),\n",
    "        \"computed_max\": float(np.max(computed_sfreqs)),\n",
    "    }\n",
    "\n",
    "    return data, freq\n",
    "\n",
    "\n",
    "def create_epochs_from_global_raw(global_raw, events, event_id, tmin=0, tmax=None):\n",
    "    \"\"\"Create an Epochs object from the global Raw dataset.\"\"\"\n",
    "    if tmax is None:\n",
    "        event_samples = events[:, 0]\n",
    "        # Append the total number of samples to compute the last trial length\n",
    "        trial_lengths = np.diff(np.append(event_samples, global_raw.n_times))\n",
    "        min_length = np.min(trial_lengths)\n",
    "        tmax = (min_length - 1) / global_raw.info[\"sfreq\"]\n",
    "\n",
    "    epochs = mne.Epochs(global_raw, events, event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def create_global_raw(data, sfreq):\n",
    "    \"\"\"Construct a global Raw object from a hierarchical dataset.\"\"\"\n",
    "    all_raws = []\n",
    "    events = []\n",
    "    event_id = {}\n",
    "    current_sample = 0  # This keeps track of the sample index in the concatenated raw.\n",
    "    next_event_code = 1\n",
    "\n",
    "    for category in data:\n",
    "        if category not in event_id:\n",
    "            event_id[category] = next_event_code\n",
    "            next_event_code += 1\n",
    "        for person in data[category]:\n",
    "            # Ensure consistent ordering of sequences (trials)\n",
    "            for seq in sorted(data[category][person].keys()):\n",
    "                raw = data[category][person][seq]\n",
    "                n_samples = raw.n_times\n",
    "                # Append an event at the start of this trial\n",
    "                events.append([current_sample, 0, event_id[category]])\n",
    "                all_raws.append(raw)\n",
    "                current_sample += n_samples\n",
    "\n",
    "    global_raw = mne.concatenate_raws(all_raws)\n",
    "    events = np.array(events)\n",
    "    return global_raw, events, event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_signal(raw_list):\n",
    "    \"\"\"Compute the trial-average (ERP) from a list of Raw objects.\"\"\"\n",
    "    # Extract data from each trial\n",
    "    data_arrays = [raw.get_data() for raw in raw_list]\n",
    "    data_stack = np.stack(data_arrays, axis=0)  # shape: (n_trials, n_channels, n_samples)\n",
    "    avg_signal = np.mean(data_stack, axis=0)  # mean over trials\n",
    "    return avg_signal\n",
    "\n",
    "\n",
    "def plot_raw_data(raw):\n",
    "    \"\"\"Visualize raw EEG data using MNE's built-in plotting function.\"\"\"\n",
    "    raw.plot(n_channels=len(raw.ch_names), show=True)\n",
    "\n",
    "\n",
    "def plot_average_signal(avg_signal, sfreq, ch_names, category_name):\n",
    "    \"\"\"Plot the average EEG signal for a given category.\"\"\"\n",
    "    n_samples = avg_signal.shape[1]\n",
    "    times = np.arange(n_samples) / sfreq  # convert sample indices to time (s)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for idx, ch in enumerate(ch_names):\n",
    "        plt.plot(times, avg_signal[idx, :], label=ch)\n",
    "    plt.title(f\"Average EEG Signal for category: {category_name}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (µV)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_SFREQ = True\n",
    "SFREQ = 256\n",
    "\n",
    "data, freq = load_all_data(\"../ufal_emmt/preprocessed-data/eeg/\", SFREQ, COMPUTE_SFREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a global Raw dataset by concatenating individual trials\n",
    "global_raw, events, event_id = create_global_raw(data, SFREQ)\n",
    "print(\"Global Raw dataset created with shape:\", global_raw.get_data().shape)\n",
    "print(\"Event markers (first few):\", events[:5])\n",
    "\n",
    "# Create Epochs from the global Raw dataset\n",
    "epochs = create_epochs_from_global_raw(global_raw, events, event_id)\n",
    "print(\"Epochs object created with\", len(epochs), \"epochs.\")\n",
    "\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Analysis Section -----\n",
    "def compute_global_erp(epochs):\n",
    "    \"\"\"Compute the global event-related potential (ERP) by averaging all epochs.\"\"\"\n",
    "    evoked = epochs.average()\n",
    "    return evoked\n",
    "\n",
    "\n",
    "def compute_category_erp(epochs, event_id):\n",
    "    \"\"\"Compute the average ERP for each category.\"\"\"\n",
    "    erp_dict = {}\n",
    "    for category in event_id.keys():\n",
    "        category_epochs = epochs[category]\n",
    "        erp_dict[category] = category_epochs.average()\n",
    "    return erp_dict\n",
    "\n",
    "\n",
    "def compute_power_spectral_density(raw, fmin=1.0, fmax=50.0):\n",
    "    \"\"\"\n",
    "    Compute the power spectral density (PSD) of the global raw signal using Welch's method.\n",
    "    \"\"\"\n",
    "    psds, freqs = mne.time_frequency.psd_welch(raw, fmin=fmin, fmax=fmax)\n",
    "    return psds, freqs\n",
    "\n",
    "\n",
    "def compute_time_frequency(epochs, freqs=np.arange(6, 30, 2), n_cycles=2, use_fft=True, return_itc=False):\n",
    "    \"\"\"Compute time-frequency representations (TFR) of the epochs using Morlet wavelets.\"\"\"\n",
    "    power = mne.time_frequency.tfr_morlet(\n",
    "        epochs,\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        use_fft=use_fft,\n",
    "        return_itc=return_itc,\n",
    "        decim=3,\n",
    "    )\n",
    "    return power\n",
    "\n",
    "\n",
    "def compute_inter_trial_variability(epochs):\n",
    "    \"\"\"Compute the inter-trial variability (standard deviation) across epochs for each channel.\"\"\"\n",
    "    data_stack = epochs.get_data()  # shape: (n_epochs, n_channels, n_times)\n",
    "    variability = np.std(data_stack, axis=0)\n",
    "    return variability\n",
    "\n",
    "\n",
    "# 1. Compute and plot the global ERP\n",
    "global_erp = compute_global_erp(epochs)\n",
    "print(\"Global ERP\")\n",
    "global_erp.plot()\n",
    "\n",
    "# 2. Compute category-specific ERP and plot one example (e.g., 'Read')\n",
    "category_erps = compute_category_erp(epochs, event_id)\n",
    "if \"Read\" in category_erps:\n",
    "    print(\"ERP for Category: Read\")\n",
    "    category_erps[\"Read\"].plot()\n",
    "\n",
    "# 3. Compute and plot the power spectral density of the global raw signal\n",
    "psds, freqs = compute_power_spectral_density(global_raw, fmin=1.0, fmax=50.0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(freqs, psds.mean(axis=0))\n",
    "plt.title(\"Global Power Spectral Density\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Compute time-frequency representation using Morlet wavelets\n",
    "tfr = compute_time_frequency(epochs, freqs=np.arange(6, 30, 2), n_cycles=2)\n",
    "tfr.plot(baseline=(None, 0), mode=\"logratio\", title=\"Time-Frequency Representation\")\n",
    "\n",
    "# 5. Compute inter-trial variability and plot for the first channel\n",
    "variability = compute_inter_trial_variability(epochs)\n",
    "times = epochs.times\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(times, variability[0, :])\n",
    "plt.title(\"Inter-Trial Variability (First Channel)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Standard Deviation (µV)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
