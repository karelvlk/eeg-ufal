{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "#  AUDIO / GAZE helpers  (unchanged API, new **relative** time axis)\n",
    "# ------------------------------------------------------------\n",
    "import io, librosa, numpy as np, pandas as pd\n",
    "from typing import Any, List, Dict\n",
    "\n",
    "\n",
    "def _audio_to_dataframe(audio_like: Any, *, target_sr: int | None = 1000, col_name: str = \"Amplitude\") -> pd.DataFrame:\n",
    "    if isinstance(audio_like, pd.DataFrame):\n",
    "        data_cols = audio_like.columns.difference([\"TimeStamp\"]).tolist()\n",
    "        return audio_like.rename(columns={data_cols[0]: col_name}).copy()\n",
    "\n",
    "    if isinstance(audio_like, tuple) and len(audio_like) == 2:\n",
    "        samples, sr = audio_like\n",
    "    else:\n",
    "        if isinstance(audio_like, (io.IOBase, io.BytesIO)):\n",
    "            audio_like.seek(0)\n",
    "        samples, sr = librosa.load(audio_like, sr=None, mono=True)\n",
    "\n",
    "    if target_sr and sr != target_sr:\n",
    "        samples = librosa.resample(samples, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "\n",
    "    # ----- relative timeline (Timedelta index) ---------------------------\n",
    "    ts = pd.to_timedelta(np.arange(len(samples)) / sr, unit=\"s\")\n",
    "    return pd.DataFrame({\"TimeStamp\": ts, col_name: samples})\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  _gaze_to_dataframe  — add empty-frame guard\n",
    "# ------------------------------------------------------------\n",
    "def _gaze_to_dataframe(\n",
    "    gaze_df: pd.DataFrame, *, window_size: float | None = None, intensity_col: str = \"Gaze_Intensity\"\n",
    ") -> pd.DataFrame:\n",
    "    g = gaze_df.copy()\n",
    "    g[\"X\"] = pd.to_numeric(g[\"X\"], errors=\"coerce\")\n",
    "    g[\"Y\"] = pd.to_numeric(g[\"Y\"], errors=\"coerce\")\n",
    "    g[\"TimeDT\"] = pd.to_datetime(g[\"TimeStamp\"], format=\"%H:%M:%S.%f\", errors=\"coerce\")\n",
    "    g = g.dropna(subset=[\"TimeDT\", \"X\", \"Y\"]).sort_values(\"TimeDT\")\n",
    "\n",
    "    # ---------- NEW: if nothing left, return empty shell -----------------\n",
    "    if g.empty:\n",
    "        return pd.DataFrame(columns=[\"TimeStamp\", intensity_col])\n",
    "\n",
    "    # ---------- movement & intensity ------------------------------------\n",
    "    g[\"dX\"] = g[\"X\"].diff().abs()\n",
    "    g[\"dY\"] = g[\"Y\"].diff().abs()\n",
    "    g[\"intensity\"] = g[\"dX\"] + g[\"dY\"]\n",
    "\n",
    "    if window_size:\n",
    "        g[\"elapsed\"] = (g[\"TimeDT\"] - g[\"TimeDT\"].iloc[0]).dt.total_seconds()\n",
    "        g[\"bin\"] = np.floor(g[\"elapsed\"] / window_size).astype(int)\n",
    "        grp = g.groupby(\"bin\")[\"intensity\"].sum()\n",
    "        max_delta = grp.max() or 1\n",
    "        grp = grp / max_delta\n",
    "        ts = pd.to_timedelta(grp.index * window_size, unit=\"s\")\n",
    "        return pd.DataFrame({\"TimeStamp\": ts, intensity_col: grp.values})\n",
    "\n",
    "    ts = g[\"TimeDT\"] - g[\"TimeDT\"].iloc[0]  # relative timeline\n",
    "    return pd.DataFrame({\"TimeStamp\": ts, intensity_col: g[\"intensity\"].values})\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "#  Correlation helper – only _prep() changed\n",
    "# ------------------------------------------------------------\n",
    "def compute_correlations(\n",
    "    eeg_df: pd.DataFrame,\n",
    "    raw_gaze_df: pd.DataFrame,\n",
    "    audio_like: Any,\n",
    "    *,\n",
    "    eeg_chans: List[str] | None = None,\n",
    "    gaze_window_size: float | None = None,\n",
    "    gaze_col: str | None = None,\n",
    "    resample_ms: int | None = 100,\n",
    "    method: str = \"pearson\",\n",
    ") -> Dict[str, float]:\n",
    "    if eeg_chans is None:\n",
    "        eeg_chans = [\"RAW_TP9\", \"RAW_AF7\", \"RAW_AF8\", \"RAW_TP10\"]\n",
    "\n",
    "    if gaze_col is None:\n",
    "        gaze_df = _gaze_to_dataframe(raw_gaze_df, window_size=gaze_window_size)\n",
    "        gaze_col = \"Gaze_Intensity\"\n",
    "    else:\n",
    "        gaze_df = raw_gaze_df\n",
    "\n",
    "    # ---------------- relative index helper ------------------------------\n",
    "    def _prep(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "        # empty guard\n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=cols)\n",
    "\n",
    "        d = df.copy()\n",
    "        ts = d[\"TimeStamp\"]\n",
    "\n",
    "        # if not already a TimedeltaIndex, convert and make relative\n",
    "        if not pd.api.types.is_timedelta64_dtype(ts.dtype):\n",
    "            ts = pd.to_datetime(ts)  # parse wall‐clock times\n",
    "            ts = ts - ts.iloc[0]  # make relative\n",
    "        # else: ts is already a TimedeltaIndex\n",
    "\n",
    "        d = d.set_index(ts)[cols]\n",
    "\n",
    "        if resample_ms is not None:\n",
    "            d = d.resample(f\"{resample_ms}ms\").mean()\n",
    "\n",
    "        return d\n",
    "\n",
    "    eeg_r = _prep(eeg_df, eeg_chans)\n",
    "    audio_r = _prep(_audio_to_dataframe(audio_like, col_name=\"AUDIO\"), [\"AUDIO\"])\n",
    "    gaze_r = _prep(gaze_df, [gaze_col]).rename(columns={gaze_col: \"GAZE\"})\n",
    "\n",
    "    merged = pd.concat([eeg_r, audio_r, gaze_r], axis=1).dropna()\n",
    "    merged[\"EEG_mean\"] = merged[eeg_chans].mean(axis=1)\n",
    "\n",
    "    corr = {\n",
    "        \"4ch_audio\": float(merged[\"EEG_mean\"].corr(merged[\"AUDIO\"], method=method)),\n",
    "        \"4ch_gaze\": float(merged[\"EEG_mean\"].corr(merged[\"GAZE\"], method=method)),\n",
    "    }\n",
    "    for ch in eeg_chans:\n",
    "        corr[f\"{ch}_audio\"] = float(merged[ch].corr(merged[\"AUDIO\"], method=method))\n",
    "        corr[f\"{ch}_gaze\"] = float(merged[ch].corr(merged[\"GAZE\"], method=method))\n",
    "\n",
    "    return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src.file_loader import FileLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    \"RAW_TP9\": \"tab:blue\",\n",
    "    \"RAW_AF7\": \"tab:orange\",\n",
    "    \"RAW_AF8\": \"tab:green\",\n",
    "    \"RAW_TP10\": \"tab:red\",\n",
    "}\n",
    "gray_shade = {\n",
    "    \"RAW_TP9\": \"gray\",\n",
    "    \"RAW_AF7\": \"dimgray\",\n",
    "    \"RAW_AF8\": \"darkgray\",\n",
    "    \"RAW_TP10\": \"slategray\",\n",
    "}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "def _mad(x: pd.Series) -> float:\n",
    "    \"\"\"Median absolute deviation scaled to σ.\"\"\"\n",
    "    return 1.4826 * np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "def is_eeg_record_valid(\n",
    "    eeg_df: pd.DataFrame,\n",
    "    *,\n",
    "    # ----------- thresholds you may want to tune ------------------\n",
    "    flat_mad_thr: float = 2.5,  #  ≲  2.5  Muse-raw units ⇒ flat\n",
    "    wild_mad_thr: float = 120,  #  ≳ 120 units ⇒ wild\n",
    "    wild_jump_thr: float = 150,  # 95-th pct(|Δ|) ≳ 150 ⇒ wild\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    {channel_name: (is_valid: bool, explanation: str)}\n",
    "    \"\"\"\n",
    "    chans = [\"RAW_TP9\", \"RAW_AF7\", \"RAW_AF8\", \"RAW_TP10\"]\n",
    "    sig = eeg_df[chans].astype(float)\n",
    "\n",
    "    results = {}\n",
    "    for ch in chans:\n",
    "        s = sig[ch].dropna()\n",
    "        mad = _mad(s)\n",
    "        p95_jump = s.diff().abs().quantile(0.95)\n",
    "\n",
    "        # ---------------- failure modes ----------------------------\n",
    "        if mad < flat_mad_thr:\n",
    "            results[ch] = (False, f\"MAD {mad:.1f} < {flat_mad_thr})\")\n",
    "        elif mad > wild_mad_thr or p95_jump > wild_jump_thr:\n",
    "            results[ch] = (\n",
    "                False,\n",
    "                f\"MAD {mad:.0f} > {wild_mad_thr} or \" f\"95-pct|Δ| {p95_jump:.0f} > {wild_jump_thr})\",\n",
    "            )\n",
    "        else:\n",
    "            results[ch] = (True, \"normal\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def data_generator():\n",
    "    loader = FileLoader(base_path=\"../ufal_emmt\")\n",
    "    data_units = loader.get_data_files(\n",
    "        category_filter=\"Read\", participant_id_filter=None, sentence_id_filter=None, sort_by=\"participant_id\"\n",
    "    )\n",
    "\n",
    "    print(data_units[0])\n",
    "\n",
    "    for read_data_unit in data_units:\n",
    "        participant_id = read_data_unit[\"participant_id\"]\n",
    "        sentence_id = read_data_unit[\"sentence_id\"]\n",
    "\n",
    "        translate_data_units = loader.get_data_files(\n",
    "            category_filter=\"Translate\", participant_id_filter=participant_id, sentence_id_filter=sentence_id\n",
    "        )\n",
    "        see_data_units = loader.get_data_files(\n",
    "            category_filter=\"See\", participant_id_filter=participant_id, sentence_id_filter=sentence_id\n",
    "        )\n",
    "        update_data_units = loader.get_data_files(\n",
    "            category_filter=\"Update\", participant_id_filter=participant_id, sentence_id_filter=sentence_id\n",
    "        )\n",
    "\n",
    "        rd = loader.load_data(read_data_unit)\n",
    "        td = loader.load_data(translate_data_units[0])\n",
    "        sd = loader.load_data(see_data_units[0])\n",
    "        ud = loader.load_data(update_data_units[0])\n",
    "\n",
    "        yield (rd, td, sd, ud), read_data_unit\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1)  Helper that yields the 32 four-tuples for one participant\n",
    "# ------------------------------------------------------------\n",
    "def participant_sequences(loader: FileLoader, participant_id: str):\n",
    "    \"\"\"\n",
    "    Yields exactly 32 tuples (rd, td, sd, ud) for the requested participant,\n",
    "    ordered by the `order` field (1‒32).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loader : FileLoader\n",
    "    participant_id : str\n",
    "    \"\"\"\n",
    "    read_units = loader.get_data_files(\n",
    "        category_filter=\"Read\",\n",
    "        participant_id_filter=participant_id,\n",
    "        sentence_id_filter=None,\n",
    "        sort_by=\"order\",\n",
    "    )\n",
    "\n",
    "    if len(read_units) != 32:\n",
    "        raise ValueError(f\"Expected 32 Read units, found {len(read_units)} for participant {participant_id}\")\n",
    "\n",
    "    for read_du in read_units:  # already sorted by order\n",
    "        sentence_id = read_du[\"sentence_id\"]\n",
    "\n",
    "        # One data-unit per category & sentence\n",
    "        translate_dus = loader.get_data_files(\"Translate\", participant_id, sentence_id)\n",
    "        see_dus = loader.get_data_files(\"See\", participant_id, sentence_id)\n",
    "        update_dus = loader.get_data_files(\"Update\", participant_id, sentence_id)\n",
    "\n",
    "        if len(translate_dus) == 1 and len(see_dus) == 1 and len(update_dus) == 1:\n",
    "            translate_du = translate_dus[0]\n",
    "            see_du = see_dus[0]\n",
    "            update_du = update_dus[0]\n",
    "        else:\n",
    "            missing = \"translate \" if len(translate_dus) == 0 else \"\"\n",
    "            missing += \"see \" if len(see_dus) == 0 else \"\"\n",
    "            missing += \"update\" if len(update_dus) == 0 else \"\"\n",
    "            print(f\"Skipping participant {participant_id} and sentence {sentence_id}, missing parts: {missing}\")\n",
    "            continue\n",
    "\n",
    "        yield (\n",
    "            loader.load_data(read_du),\n",
    "            loader.load_data(translate_du),\n",
    "            loader.load_data(see_du),\n",
    "            loader.load_data(update_du),\n",
    "            read_du[\"order\"],  # keep the order number for sorting/plotting\n",
    "        )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2)  Plot all 32 sequences for one participant in one figure\n",
    "# ------------------------------------------------------------\n",
    "def plot_participant_eeg(participant_id: str, base_path: str = \"../ufal_emmt\"):\n",
    "    \"\"\"\n",
    "    Creates a 32×4 figure:\n",
    "        • rows  = order 1‒32\n",
    "        • cols  = Read | Translate | See | Update\n",
    "    \"\"\"\n",
    "    loader = FileLoader(base_path=base_path)\n",
    "    seq_iter = sorted(participant_sequences(loader, participant_id), key=lambda x: x[-1])  # just in case\n",
    "\n",
    "    fig, axes = plt.subplots(32, 4, figsize=(20, 2 * 32 + 2), sharey=\"row\", constrained_layout=True)\n",
    "    plt.subplots_adjust(hspace=0.6)\n",
    "    col_labels = [\"Read\", \"Translate\", \"See\", \"Update\"]\n",
    "\n",
    "    for row_idx, (rd, td, sd, ud, order) in enumerate(seq_iter):\n",
    "        for col_idx, (eeg_df, label) in enumerate(zip([rd[0], td[0], sd[0], ud[0]], col_labels)):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "\n",
    "            # validity & colour selection (as in your code)\n",
    "            results = is_eeg_record_valid(eeg_df)\n",
    "            eeg_df[\"TimeStamp\"] = pd.to_datetime(eeg_df[\"TimeStamp\"], format=\"%H:%M:%S.%f\")\n",
    "\n",
    "            for ch, ch_label in zip(\n",
    "                [\"RAW_TP9\", \"RAW_AF7\", \"RAW_AF8\", \"RAW_TP10\"],\n",
    "                [\"TP9\", \"AF7\", \"AF8\", \"TP10\"],\n",
    "            ):\n",
    "                ok, reason = results[ch]\n",
    "                colour = color_map[ch] if ok else gray_shade[ch]\n",
    "                ax.plot(eeg_df[\"TimeStamp\"], eeg_df[ch], colour, label=ch_label)\n",
    "\n",
    "            # only add legend on first row to keep the figure tidy\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(label)\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(f\"order {order}\")\n",
    "            if row_idx == 31:  # last row\n",
    "                ax.set_xlabel(\"Time\")\n",
    "            ax.grid(True)\n",
    "\n",
    "    # put one common legend outside the grid\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.00),  # exactly at the top edge\n",
    "        ncol=4,\n",
    "        frameon=False,\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"EEG – participant {participant_id}\",\n",
    "        y=0.97,  # inside the figure now\n",
    "        fontsize=18,\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pids = sorted(set(du[\"participant_id\"] for du in FileLoader(\"../ufal_emmt\").get_data_files(category_filter=\"Read\")))\n",
    "# for pid in all_pids:\n",
    "#     plot_participant_eeg(pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "g = data_generator()\n",
    "n = 0\n",
    "for (rd, td, sd, ud), du in g:\n",
    "    if n > 100:\n",
    "        break\n",
    "    n += 1\n",
    "\n",
    "    r_eeg_df, r_gaze_df, r_audio_io = rd\n",
    "    t_eeg_df, t_gaze_df, t_audio_io = td\n",
    "    s_eeg_df, s_gaze_df, s_audio_io = sd\n",
    "    u_eeg_df, u_gaze_df, u_audio_io = ud\n",
    "\n",
    "    r_corr = compute_correlations(*rd)\n",
    "    t_corr = compute_correlations(*td)\n",
    "    s_corr = compute_correlations(*sd)\n",
    "    u_corr = compute_correlations(*ud)\n",
    "\n",
    "    print(f\"Read correlations  : {r_corr}\")\n",
    "    print(f\"Translate corr.    : {t_corr}\")\n",
    "    print(f\"See correlations   : {s_corr}\")\n",
    "    print(f\"Update correlations: {u_corr}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 6), sharey=True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Make room for the suptitle\n",
    "    plt.suptitle(\n",
    "        f\"EEG | participant_id: {du['participant_id']} | sentence_id: {du['sentence_id']} | order: {du['order']}\",\n",
    "        fontsize=16,\n",
    "    )\n",
    "\n",
    "    for i, (eeg_df, label, ax) in enumerate(\n",
    "        zip([r_eeg_df, t_eeg_df, s_eeg_df, u_eeg_df], [\"Read\", \"Translate\", \"See\", \"Update\"], axes)\n",
    "    ):\n",
    "        # Compute validity\n",
    "        results = is_eeg_record_valid(eeg_df)\n",
    "        overall_valid = all(ok for ok, _ in results.values())\n",
    "\n",
    "        # Convert TimeStamp\n",
    "        eeg_df[\"TimeStamp\"] = pd.to_datetime(eeg_df[\"TimeStamp\"], format=\"%H:%M:%S.%f\")\n",
    "\n",
    "        # Plot each channel\n",
    "        for ch, ch_label in zip([\"RAW_TP9\", \"RAW_AF7\", \"RAW_AF8\", \"RAW_TP10\"], [\"TP9\", \"AF7\", \"AF8\", \"TP10\"]):\n",
    "            ok, reason = results[ch]\n",
    "            color = color_map[ch] if ok else gray_shade[ch]\n",
    "            ax.plot(eeg_df[\"TimeStamp\"], eeg_df[ch], label=ch_label, color=color)\n",
    "            print(f\"{label} - {ch:7s} -> {'OK' if ok else 'BAD'} | {reason}\")\n",
    "\n",
    "        ax.set_title(f\"{label} EEG\\nValid: {overall_valid}\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.grid(True)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Amplitude\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
